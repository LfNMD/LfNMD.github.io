![TMM_masthead](asserts/TMM_masthead.png)




# <center><font color=red>Call for Papers: IEEE [TMM](https://signalprocessingsociety.org/publications-resources/ieee-transactions-multimedia) Special Issue</font></center>

### IEEE Transactions on Multimedia Special Issue on <font color=blue>Learning from Noisy Multimedia Data</font>



#### Motivations and Topics

With the development of computing power and deep learning algorithms, we can process and apply millions or even hundreds of millions of large-scale data to train robust models. Nevertheless, constructing a million-scale dataset like ImageNet is time-consuming and labor-intensive. Fortunately, web data are rich and free resources. For arbitrary categories, the potential training data can be easily obtained from the web (e.g., search engines such as Google and Bing, Twitter, Instagram, and short video sharing applications). Moreover, with the development of the Internet, web data consist of much richer modality, such as text, audio, image, and video. It is consequently natural to leverage the large-scale yet noisy data on the web to automatically construct various types of datasets. However, there are two critical issues in the automatically collected datasets: “label noise” and “domain mismatch”. Learning directly from noisy web data tends to have poor performance.

This special issue serves as a forum for researchers all over the world to discuss their works and recent advances in learning from noisy web data. Both state-of-the-art articles, as well as comprehensive literature reviews, are welcome for submission. To provide readers of the special issue with an understanding of the most current issues in this field, we will invite one survey paper, which will undergo peer review. Papers addressing interesting real-world multimedia as well as computer vision applications are especially encouraged.

The special issue seeks original contributions which address the challenges in learning from noisy web data. Possible topics include but are not limited to:

- Webly supervised visual classification, detection, segmentation, and feature learning

- Large-scale/web-scale noisy data learning systems
- Label noise in deep learning, theoretical analysis, and application
- Automatic image dataset construction and application
- Multi-modality theoretical analysis and application
- Data augmentation theoretical analysis and application
- Transfer learning across labeled and web data
- New datasets and benchmarks for webly supervised learning



####  List of Potential Contributors

This special issue seeks contributions from all over the world, including universities, research institutions, companies. We expect 60+ submissions and will accept 20~22 submissions.



#### Submission Guideline

Authors should prepare their manuscript according to the Guide for Authors available from the online submission page of the IEEE Transactions on Multimedia at https://journals.ieeeauthorcenter.ieee.org/submit-your-article-for-peer-review/the-ieee-article-submission-process. All papers will be peer-reviewed following the IEEE Transactions on Multimedia reviewing procedures.



####  The Proposed Schedule is given below

- Paper submission due:  	   	  	    <font color=red>**Oct. 15, 2020**</font>
- First review notification: 			 Jan. 15, 2021
- Revision submission: 				    March 15, 2021
- Second review notification: 	    May 15, 2021
- Acceptance notification: 		     July 15, 2021



#### Managing Guest Editor

A/Prof. Jian Zhang, University of Technology Sydney, Australia ([jian.zhang@uts.edu.au](mailto:jian.zhang@uts.edu.au))



#### Guest Editors

Prof. Alan Hanjalic, Delft University of Technology, The Netherland ([A.Hanjalic@tudelft.nl](mailto:A.Hanjalic@tudelft.nl))

Prof. Ramesh Jain, University of California - Irvine, CA, USA (jain@ics.uci.edu)

Dr. Xiansheng Hua, DAMO Academy, Alibaba Group, Hangzhou, China (huaxiansheng@gmail.com)

Prof. Yazhou Yao, Nanjing University of Science and Technology, China (yazhou.yao@njust.edu.cn)

Prof. Den Zeng, Shanghai University, China (dzeng@shu.edu.cn)

